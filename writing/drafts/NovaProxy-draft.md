# 《保姆级教程：手把手教你在 Claude Code 里免费用上 GLM-4 和 Minimax！》

相信我，如果你也在用 Anthropic 最近刚出的那个 **Claude Code** 终端工具，你一定跟我一样，既爱死它的效率，又恨死它的“高冷”。

API 贵得要命不说，国内连接还经常各种不稳定。看着余额像流水一样花出去，心里多多少少有点心疼。

**但如果我说，今天只需要 5 分钟，我就能让你在 Claude Code 里白嫖上国产之光 GLM-4 和 Minimax，而且配置简单到离谱，你跟不跟我学？**

今天我们要用到两个压箱底的神器：一个是专门负责协议转换的 **NovaProxy**，另一个是负责一键切换引擎的 **cc-switch**。

废话不多说，直接上干货！

---

## 第一步：准备好你的“能量块”（NVIDIA API Key）

我们要薅的羊毛来自 NVIDIA 的 NIM 平台。为什么选它？因为目前它给 GLM-4 和 Minimax 提供了大量的免费或极低成本的额度，而且速度奇快！

1. 访问 NVIDIA API 列表，随便找个模型（比如 GLM-4-9B）。
2. 点击生成 `nvapi-xxx` 格式的密钥。
3. 把这串码记下来，它是我们接下来的动力来源。

---

## 第二步：架起桥梁——NovaProxy

这时候，你可能会问：NVIDIA 的接口是 OpenAI 格式的，Claude Code 不认怎么办？

这时候就轮到 **NovaProxy** 出场了。它就是专门干“翻译”活儿的。

1. **下载 NovaProxy**：直接运行 `NovaProxy.exe`。
2. **自动弹窗**：这软件极简到了极点，启动后会自动弹出浏览器后台。
3. **暖沙审美**：你会看到一个非常温馨的“暖沙色”界面（说实话，这审美比那些冷冰冰的黑色终端好太多了）。
4. **填 Key 保存**：在设置框里直接粘贴你刚才拿到的 NVIDIA Key，点击**保存**。

**此时，你的本地已经跑起了一个“伪装”成 Claude 官方服务器的桥梁，地址就是：`http://localhost:3001/v1`。**

---

## 第三步：暴力破拆——cc-switch 登场

Claude Code 官方很顽固，它默认只认自家的地址。我们要想让它“改道”走我们的本地桥梁，需要用到 **cc-switch** (感谢开发者 `farion1231`)。

1. **安装 cc-switch**：按照 GitHub 上的说明一键安装。
2. **添加新节点**：在 cc-switch 里新增一个配置：
   - **名称**：`Nova-GLM`（随便起）
   - **Base URL**：填入 `http://localhost:3001/v1`
   - **API Key**：随便填几个字母（因为我们在 NovaProxy 里没设暗号）。
3. **一键切换**：执行 `cc-switch switch Nova-GLM`。

**这一步做完，当你运行 `claude` 时，它就会乖乖地顺着 cc-switch 指的路，通过 NovaProxy 访问到 NVIDIA 的模型了！**

---

## 第四步：见证奇迹的时刻

现在，回到你的终端项目目录下，像往常一样输入：

```bash
claude
# 如果你想更爽一点，可以用：
claude --dangerously-skip-permissions
```

你会惊讶地发现，那个熟悉的小眼睛又转起来了！但不同的是，这次后台跑的是国产最强的 **GLM-4** 或者 **Minimax**。

我实测了一下，写前端组件、改 Python Bug，这套组合拳的响应速度甚至比原生的 Claude 还要快，最重要的是：**它几乎不花钱！**

---

## 写在最后

其实折腾这些，不只是为了省钱，更多的是为了那种“模型自由”的掌控感。

**NovaProxy** 负责美和兼容，**cc-switch** 负责灵活和切换。两个国产工具的联动，硬生生把 Claude Code 这个贵族工具改造成了咱们平民也能天天用的生产力大杀器。

如果你在配置过程中遇到了什么报错，或者发现哪个模型表现更神，欢迎在评论区留言。

**转发这篇文章给还没实现“模型自由”的朋友，咱们顶峰见！**
